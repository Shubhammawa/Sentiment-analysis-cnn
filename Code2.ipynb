{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"../Sentiment-analysis-cnn/sentiment labelled sentences\",dtype=object,na_values=str).values\n",
    "#df = pd.read_fwf('../Sentiment-analysis-cnn/sentiment labelled sentences/imdb_labelled.txt')\n",
    "#df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Sentiment-analysis-cnn/sentiment labelled sentences/imdb_labelled.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open('train.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Sentence', 'Category'))\n",
    "        writer.writerows(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv(\"../Sentiment-analysis-cnn/sentiment labelled sentences/imdb_labelled.txt\",delimiter=\"\\t\")\n",
    "# dataframe.to_csv(\"NewProcessedDoc.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../Sentiment-analysis-cnn/sentiment labelled sentences/imdb_labelled.txt', \"r\",newline='') as in_text:\n",
    "#     in_reader = csv.reader(in_text, dialect='excel-tab')\n",
    "#     with open('train2.csv', \"w\") as out_csv:\n",
    "#         out_writer = csv.writer(out_csv,dialect='excel')\n",
    "#         for row in in_reader:\n",
    "#             out_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string2 = ';) Recommend with confidence!\\t1'\n",
    "# string = 'how he became the emperor; nothing about where he spend 20 years\\t0'\n",
    "# print(string.strip())\n",
    "# print(string.strip(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(string.strip().split('\\t'))\n",
    "# print(string.strip(';').split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# emoji_pattern = re.compile(\"[\"\n",
    "#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            \"]+\", flags=re.UNICODE)\n",
    "# text = ';) Recommend with confidence!\\t1'\n",
    "# print(emoji_pattern.sub(r'',text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train1.csv\",dtype=object,na_values=str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  '\n",
      "  '0']\n",
      " ['Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  '\n",
      "  '0']\n",
      " ['Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  '\n",
      "  '0']\n",
      " ['Very little music or anything to speak of.  ' '0']\n",
      " ['The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  '\n",
      "  '1']]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[:,0])\n",
    "y = np.array((data[:,1]))\n",
    "y = np.array([int(num) for num in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.int64'>\n",
      "(3000,)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(x[0]))\n",
    "print(type(y[0]))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  '\n",
      " 'Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  '\n",
      " 'Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  '\n",
      " 'Very little music or anything to speak of.  ']\n"
     ]
    }
   ],
   "source": [
    "print(x[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists of words\n",
    "words = []\n",
    "sentences = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "i = 0\n",
    "for sent in x:\n",
    "    #words.append(sent.split())\n",
    "    #i = i + 1\n",
    "    #print(i)\n",
    "    for word in tokenizer.tokenize(sent):\n",
    "        words.append(word.lower())\n",
    "    sentences.append(words)\n",
    "    words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '10']\n",
      "<class 'list'>\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(sentences[788])\n",
    "print(type(sentences))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341886, 1818750)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train word vectors using Word2Vec or FastText\n",
    "\n",
    "model_word2vec = Word2Vec(sentences, size=300, window=15, min_count=0,workers=10,sg=0)\n",
    "model_word2vec.train(sentences,total_examples=len(sentences),epochs=50)\n",
    "\n",
    "# model_FastText = FastText(sentences, size=300, window=15, min_count=0,workers=10,sg=0)\n",
    "# model_FastText.train(sentences,total_examples=len(sentences),epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=5183, size=300, alpha=0.025)\n",
      "[ 0.860536   -0.5572672  -0.28367937  0.26681742 -0.64941484  0.85627204\n",
      "  0.07630259 -0.3075796  -0.68350947  0.09993773  0.20441946  0.52584827\n",
      "  0.3756405   0.00943647 -0.24991123 -0.33999842  0.55184     0.1878674\n",
      " -0.23876223  0.40546742  0.55194134  0.1960668  -0.2414565   0.2610725\n",
      " -0.5210105  -0.6659356   0.40075698 -0.05167313 -0.27334887 -0.31764522\n",
      "  0.36541882 -0.5588648  -0.15356894  0.46003994 -0.89849997  0.7829339\n",
      " -0.44989198 -0.50110126  0.6700309   1.3072382   0.29538047 -0.01343094\n",
      " -0.46648887  1.0121198   0.35508543  0.6910593  -0.06903382  0.438926\n",
      " -1.1262873   0.2084449  -1.203237    0.04428053 -0.07666764 -0.5603703\n",
      "  0.3818324   1.0918674  -0.34018546 -0.4282077   1.2880069   0.18331203\n",
      " -0.6995832   1.4992297  -0.597639    0.52585906  0.5508301   0.49900445\n",
      "  0.31931746  0.17777203 -0.78449    -0.32217896 -0.6674321   0.09309116\n",
      "  0.6853142  -0.6727469   0.2751102  -0.07918177  0.08277836 -1.110747\n",
      "  0.17689875 -0.17827554 -0.01931087 -0.10991351 -0.11367296  0.27389956\n",
      "  0.5520429   0.6534839  -0.35346726 -0.13984051  0.6855849   0.88939756\n",
      "  0.27657884  0.11820188  0.7307298   0.3720302  -0.62791604 -0.7375756\n",
      "  0.09342808  0.35251912  0.24503198 -0.90224063  0.5755973  -0.75242984\n",
      " -0.20666707  0.63790965 -1.148053    0.646048    0.8642802  -1.2716854\n",
      "  0.34156933 -0.23438263  0.4101854   0.12756714 -0.08862438 -0.89334404\n",
      " -0.01386998 -0.37760887  0.83925396  0.31463397  0.06348871 -0.1421857\n",
      " -0.12921654 -0.84363824  0.14356479 -0.05434978  0.0537293   0.49847662\n",
      "  0.04183575  0.45393902 -0.6390698   0.18670897  0.45137572 -0.16686538\n",
      "  0.15467909  0.3899045   1.3325557  -0.058407   -0.15656026  0.18604591\n",
      "  0.3715839  -0.08655631  0.2813822   0.3567419   0.51195323  0.19668141\n",
      "  0.82473356  0.11787489  0.09209635 -0.29136953  0.93689996 -0.4569755\n",
      " -0.16878325  0.68107086 -0.36149147  0.18095692 -0.47889054 -0.01854624\n",
      " -0.51875156 -0.5712322   0.7037396  -0.438298   -0.3222416   0.13923979\n",
      " -0.41091463  0.07394579  0.13948105 -0.43059233 -0.52542174  0.28864998\n",
      "  0.09599017 -0.15444756 -0.02692203 -0.02371611  0.4029602   0.11930331\n",
      "  0.43200877  0.0205607  -0.0808611  -0.41734692 -0.1495992  -0.12441073\n",
      "  0.42906362 -0.7186686   0.5105625   0.51868254  0.05944722 -0.11660904\n",
      "  0.23026162 -0.20462629  0.58011353  0.22208773  0.06200154  0.6272456\n",
      " -0.00509841 -0.04941555  0.55032605  0.48714676 -0.536819   -0.7027915\n",
      "  0.4457742  -1.150561   -0.54932845  0.9076893   0.8458994   0.10521927\n",
      " -0.05591827 -0.8617491  -0.6329118  -0.18662556 -0.8220966  -0.22780888\n",
      "  0.26007918 -0.6861311   0.28284383  0.3258375  -0.5170853   0.28764328\n",
      "  0.1640076   0.21685834 -0.10758901  0.78469485 -0.7902124   0.54365855\n",
      " -0.8603168  -1.1233405   1.0442411   0.49400827  0.42232266 -0.8175889\n",
      "  0.38455212  0.6939863  -0.5070116  -0.60047996  0.6794832  -0.332952\n",
      "  0.19601494 -0.08068602  0.23487097  0.4469138   0.05381554  0.07798278\n",
      "  0.21656135 -0.06052622  0.6214077  -0.8498584   0.813981    0.31436768\n",
      " -0.38218677  1.0684288  -0.03232506 -0.9015348  -0.03548123  0.4846963\n",
      "  0.05446458  0.05854162 -0.06489402  0.28377852  0.4653011  -1.0120269\n",
      " -0.55486435 -0.07100021  0.61552936 -0.7016579  -0.65489376 -0.35059914\n",
      " -0.6505499  -0.17534967  0.71292436  0.20389107  0.24102153  0.49715757\n",
      "  0.42589977 -0.37881434 -0.14089353 -0.7265415   0.59640163  0.85455817\n",
      "  0.7340246  -0.7480355   1.174009   -0.46538794 -0.34208798  0.689276\n",
      "  0.29836112  0.7242057  -0.14865857 -0.61097443 -0.6023469  -0.7760251\n",
      " -0.23354812 -0.15728599 -0.4016204   0.09202539  0.16049515 -0.15432449\n",
      "  0.11128248 -0.18340965 -0.77953804 -0.43783736  0.3724445   0.8683112 ]\n",
      "[('clean', 0.7612135410308838), ('camp', 0.7430263161659241), ('quick', 0.7243200540542603), ('fancy', 0.7166894674301147), ('affordable', 0.709017276763916), ('shipping', 0.6977795362472534), ('petty', 0.6975258588790894), ('impeccable', 0.6890199184417725), ('gross', 0.6881396770477295), ('engineered', 0.686336874961853)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(model_word2vec)\n",
    "print(model_word2vec['10'])\n",
    "print(model_word2vec.wv.most_similar(\"good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec.save(\"Saved_model_word2vec_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=5183, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(\"Saved_model_word2vec_train1\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "temp = []\n",
    "for i in range(0,len(sentences)):\n",
    "    for j in range(0,len(sentences[i])):\n",
    "        temp.append(model[sentences[i][j]])\n",
    "    X.append(temp)\n",
    "    temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "620\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "max1 = 0\n",
    "for i in range(0,len(X)):\n",
    "    if(len(X[i])>max1):\n",
    "        max1 = len(X[i])\n",
    "        pos = i\n",
    "print(max1)\n",
    "print(pos)\n",
    "print(len(X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0,len(X)):\n",
    "    if(len(X[i])>32):\n",
    "        count = count + 1\n",
    "print(count)\n",
    "\n",
    "#  Sequence length : Length of each training example\n",
    "#  Sequence length is varying from 1 to 74, we have to choose a dimension and accordingly all training exapmles would be\n",
    "#  padded or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_new = keras.preprocessing.sequence.pad_sequences(sequences=X, maxlen=32, dtype='float32', padding='post', truncating='post', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 300)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Y))\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------------------CNN Model---------------------------###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(seq_length, embedding_size, n_y):\n",
    "    \n",
    "#     Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "#     Arguments:\n",
    "#     n_H0 -- scalar, height of an input image\n",
    "#     n_W0 -- scalar, width of an input image\n",
    "#     n_C0 -- scalar, number of channels of the input\n",
    "#     n_y -- scalar, number of classes\n",
    "        \n",
    "#     Returns:\n",
    "#     X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "#     Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(dtype = tf.float32, shape=(None,seq_length,embedding_size,1))\n",
    "    Y = tf.placeholder(dtype = tf.float32, shape=(None,n_y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_parameters(filter_size,embedding_size,num_filters):\n",
    "#     # Initializes weight parameters\n",
    "#     W = tf.get_variable(\"W\",[filter_size,embedding_size,1,num_filters],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer(seed=0),regularizer = tf.contrib.layers.l2_regularizer(scale=0.1))\n",
    "#     return W\n",
    "\n",
    "def initialize_parameters(filter_sizes,embedding_size,num_filters):\n",
    "    # Initializes weight parameters\n",
    "    W1 = tf.get_variable(\"W1\",[filter_sizes[0],embedding_size,1,num_filters],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer(seed=0),regularizer = tf.contrib.layers.l2_regularizer(scale=0.1))\n",
    "    W2 = tf.get_variable(\"W2\",[filter_sizes[1],embedding_size,1,num_filters],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer(seed=0),regularizer = tf.contrib.layers.l2_regularizer(scale=0.1))\n",
    "    W3 = tf.get_variable(\"W3\",[filter_sizes[2],embedding_size,1,num_filters],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer(seed=0),regularizer = tf.contrib.layers.l2_regularizer(scale=0.1))\n",
    "    W4 = tf.get_variable(\"W4\",[filter_sizes[3],embedding_size,1,num_filters],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer(seed=0),regularizer = tf.contrib.layers.l2_regularizer(scale=0.1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3,\n",
    "                  \"W4\": W4}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_propagation(X,filter_sizes,embedding_size,num_filters,seq_length):\n",
    "#     P2 = []\n",
    "#     for filter_size in filter_sizes:\n",
    "#         W = initialize_parameters(filter_size,embedding_size,num_filters)\n",
    "#         Z = tf.nn.conv2d(X,W,strides=[1,1,1,1],padding=\"SAME\")\n",
    "#         A = tf.nn.relu(Z)\n",
    "#         P = tf.nn.max_pool(A,ksize=[1,seq_length-filter_size+1,1,1],strides=[1,1,1,1],padding=\"SAME\")\n",
    "#         P2.append(P)\n",
    "#     Z2 = tf.contrib.layers.fully_connected(P2,41,activation_fn = None)\n",
    "#     return Z2\n",
    "\n",
    "def forward_propagation(X,filter_sizes,embedding_size,num_filters,seq_length,parameters):\n",
    "    print(\"X shape:\",X.shape)\n",
    "    #P = []\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    print(\"W1 shape :\",W1.shape)\n",
    "    print(\"W2 shape :\",W2.shape)\n",
    "    print(\"W3 shape :\",W3.shape)\n",
    "    print(\"W4 shape :\",W4.shape)\n",
    "    #W1 = initialize_parameters(filter_sizes[0],embedding_size,num_filters)\n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"VALID\")\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,seq_length-filter_sizes[0]+1,1,1],strides=[1,1,1,1],padding=\"VALID\")\n",
    "    #P.append(P1)\n",
    "    print(\"Z1 shape:\",Z1.shape)\n",
    "    print(\"P1 shape:\",P1.shape)\n",
    "    #W2 = initialize_parameters(filter_sizes[1],embedding_size,num_filters)\n",
    "    Z2 = tf.nn.conv2d(X,W2,strides=[1,1,1,1],padding=\"VALID\")\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,seq_length-filter_sizes[1]+1,1,1],strides=[1,1,1,1],padding=\"VALID\")\n",
    "    #P.append(P2)\n",
    "    print(\"Z2 shape:\",Z2.shape)\n",
    "    print(\"P2 shape:\",P2.shape)\n",
    "    \n",
    "    #W3 = initialize_parameters(filter_sizes[2],embedding_size,num_filters)\n",
    "    Z3 = tf.nn.conv2d(X,W3,strides=[1,1,1,1],padding=\"VALID\")\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3,ksize=[1,seq_length-filter_sizes[2]+1,1,1],strides=[1,1,1,1],padding=\"VALID\")\n",
    "    #P.append(P3)\n",
    "    print(\"Z3 shape:\",Z3.shape)\n",
    "    print(\"P3 shape:\",P3.shape)\n",
    "    \n",
    "    #W4 = initialize_parameters(filter_sizes[3],embedding_size,num_filters)\n",
    "    Z4 = tf.nn.conv2d(X,W4,strides=[1,1,1,1],padding=\"VALID\")\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    P4 = tf.nn.max_pool(A4,ksize=[1,seq_length-filter_sizes[3]+1,1,1],strides=[1,1,1,1],padding=\"VALID\")\n",
    "    #P.append(P4)\n",
    "    print(\"Z4 shape:\",Z4.shape)\n",
    "    print(\"P4 shape:\",P4.shape)\n",
    "    #P = np.array(P)\n",
    "    P = tf.concat([P1,P2,P3,P4],3)\n",
    "    print(\"P shape:\",P.shape)\n",
    "    P = tf.contrib.layers.flatten(P)\n",
    "    print(\"P shape flattened\",P.shape)\n",
    "    Z5 = tf.contrib.layers.fully_connected(P,2,activation_fn = None)\n",
    "    print(\"Z5 shape:\",Z5.shape)\n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z5, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z5 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples,2)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z5\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z5, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size, seed = 0):\n",
    "    np.random.seed(seed)            \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    #print(\"X shape:\",X.shape)\n",
    "    #print(\"Y shape\",Y.shape)\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:]\n",
    "    #print(\"Shuffled X shape\",shuffled_X.shape)\n",
    "    shuffled_Y = Y[permutation,:]#.reshape((2,m))\n",
    "    #print(\"Shuffled Y shape\",shuffled_Y.shape)\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k*mini_batch_size:(k+1)*mini_batch_size,:]\n",
    "        mini_batch_Y = shuffled_Y[k*mini_batch_size:(k+1)*mini_batch_size,:]#.reshape((2,m))\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:m,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches*mini_batch_size:m,:]#.reshape((2,m))\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.005,\n",
    "          num_epochs = 50, minibatch_size = 32, print_cost = True):\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    \n",
    "    # To be used if not using stochastic\n",
    "    (m, seq_length, embedding_size,nc) = X_train.shape             \n",
    "    ##-----------------------------------------###\n",
    "    \n",
    "    \n",
    "    ## To be used if using Stochastic ##\n",
    "#     m = X_train.shape[0]\n",
    "#     seq_length = X_train.shape[2]\n",
    "#     embedding_size = X_train.shape[3]\n",
    "#     nc = X_train.shape[4]\n",
    "    ##------------------------------------####\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_y = Y_train.shape[1]            # 2 - stochastic;  1 - otherwise                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    filter_sizes = [2,4,7,9]\n",
    "    num_filters = 4\n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(seq_length, embedding_size, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(filter_sizes,embedding_size,num_filters)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "\n",
    "    Z5 = forward_propagation(X,filter_sizes,embedding_size,num_filters,seq_length,parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z5, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(0,num_epochs):\n",
    "            #_, temp_cost = sess.run([optimizer, cost], feed_dict = {X:X_train, Y:Y_train})  #Batch Gradient Descent\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})     # mini_batch gradieent descent\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "#             stochastic_cost=0    \n",
    "#             for i in range(0,m):\n",
    "#                 _, temp_cost = sess.run([optimizer, cost], feed_dict = {X:X_train[i], Y:Y_train[i]}) \n",
    "#                 stochastic_cost += temp_cost/m\n",
    "#                 if(i%10==0):\n",
    "#                     print(\"Cost after\",i,\"iterations =\",stochastic_cost)\n",
    "                \n",
    "            #Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "#             if print_cost == True and epoch % 5 == 0:\n",
    "#                 print (\"Cost after epoch %i: %f\" % (epoch, stochastic_cost))\n",
    "#             if print_cost == True and epoch % 1 == 0:\n",
    "#                 costs.append(stochastic_cost)\n",
    "#             if print_cost == True and epoch % 5 == 0:\n",
    "#                 print (\"Cost after epoch %i: %f\" % (epoch, temp_cost))\n",
    "#             if print_cost == True and epoch % 1 == 0:\n",
    "#                 costs.append(temp_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # Calculate the correct predictions\n",
    "        print(\"Z5 shape:\",Z5.shape)\n",
    "        predict_op = tf.argmax(Z5, 1)\n",
    "        print(\"predict_op shape:\",predict_op.shape)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y,1))\n",
    "        print(\"Correct prediction shape:\",correct_prediction.shape)\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(\"accuracy shape:\",accuracy.shape)\n",
    "        #accuracy = tf.Print(accuracy, [accuracy], message=\"Accuracy: \")\n",
    "        #print(sess.run(accuracy))\n",
    "#         train_accuracy = accuracy.eval({X: np.squeeze(X_train,axis=1), Y: np.squeeze(Y_train,axis=1)})\n",
    "#         test_accuracy = accuracy.eval({X: np.squeeze(X_test,axis=1), Y: np.squeeze(Y_test,axis=1)})\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        #precision = tf.metrics.precision(Y_test,correct_prediction)\n",
    "        #recall = tf.metrics.recall(Y_test,correct_prediction)\n",
    "        \n",
    "        #print(\"Precision =\",precision)\n",
    "        #print(\"Recall=\",recall)\n",
    "        \n",
    "        #F1_score_sklearn = f1_score()\n",
    "        #F1_score_tf = tf.contrib.metrics.f1_score(Y_test,predictions) \n",
    "        #print(\"F1_score=\",F1_score_tf)\n",
    "                \n",
    "        #return train_accuracy, test_accuracy, predict_op,parameters\n",
    "        return predict_op,correct_prediction,parameters,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 300)\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 32, 300)\n",
      "(2550, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train,axis=3)\n",
    "X_test = np.expand_dims(X_test,axis=3)\n",
    "#Y_train = np.expand_dims(Y_train,axis=1)\n",
    "#Y_test = np.expand_dims(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 32, 300, 1)\n",
      "(2550, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (?, 32, 300, 1)\n",
      "W1 shape : (2, 300, 1, 4)\n",
      "W2 shape : (4, 300, 1, 4)\n",
      "W3 shape : (7, 300, 1, 4)\n",
      "W4 shape : (9, 300, 1, 4)\n",
      "Z1 shape: (?, 31, 1, 4)\n",
      "P1 shape: (?, 1, 1, 4)\n",
      "Z2 shape: (?, 29, 1, 4)\n",
      "P2 shape: (?, 1, 1, 4)\n",
      "Z3 shape: (?, 26, 1, 4)\n",
      "P3 shape: (?, 1, 1, 4)\n",
      "Z4 shape: (?, 24, 1, 4)\n",
      "P4 shape: (?, 1, 1, 4)\n",
      "P shape: (?, 1, 1, 16)\n",
      "P shape flattened (?, 16)\n",
      "Z5 shape: (?, 2)\n",
      "Cost after epoch 0: 0.629223\n",
      "Cost after epoch 5: 0.392108\n",
      "Cost after epoch 10: 0.251798\n",
      "Cost after epoch 15: 0.152257\n",
      "Cost after epoch 20: 0.134068\n",
      "Cost after epoch 25: 0.125129\n",
      "Cost after epoch 30: 0.106292\n",
      "Cost after epoch 35: 0.062788\n",
      "Cost after epoch 40: 0.079074\n",
      "Cost after epoch 45: 0.069765\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z5 shape: (?, 2)\n",
      "predict_op shape: (?,)\n",
      "Correct prediction shape: (?,)\n",
      "accuracy shape: ()\n",
      "Train Accuracy: 0.99058825\n",
      "Test Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "predict_op,correct_prediction,parameters,accuracy = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
